{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8AuNzlyQuGDq"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data = pd.read_csv(\"database.csv\")\n",
        "data.columns"
      ],
      "metadata": {
        "id": "XsqKmuBpuWe9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data = data[['Date', 'Time', 'Latitude', 'Longitude', 'Depth', 'Magnitude']]\n",
        "data.head()"
      ],
      "metadata": {
        "id": "1zv6dEGcuY9j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import datetime\n",
        "import time\n",
        "\n",
        "timestamp = []\n",
        "for d, t in zip(data['Date'], data['Time']):\n",
        "    try:\n",
        "        ts = datetime.datetime.strptime(d+' '+t, '%m/%d/%Y %H:%M:%S')\n",
        "        timestamp.append(time.mktime(ts.timetuple()))\n",
        "    except ValueError:\n",
        "        # print('ValueError')\n",
        "        timestamp.append('ValueError')\n",
        "timeStamp = pd.Series(timestamp)\n",
        "data['Timestamp'] = timeStamp.values\n",
        "final_data = data.drop(['Date', 'Time'], axis=1)\n",
        "final_data = final_data[final_data.Timestamp != 'ValueError']\n",
        "final_data.head()"
      ],
      "metadata": {
        "id": "s1VfsFUZubc6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from mpl_toolkits.basemap import Basemap\n",
        "\n",
        "m = Basemap(projection='mill',llcrnrlat=-80,urcrnrlat=80, llcrnrlon=-180,urcrnrlon=180,lat_ts=20,resolution='c')\n",
        "\n",
        "longitudes = data[\"Longitude\"].tolist()\n",
        "latitudes = data[\"Latitude\"].tolist()\n",
        "#m = Basemap(width=12000000,height=9000000,projection='lcc',\n",
        "            #resolution=None,lat_1=80.,lat_2=55,lat_0=80,lon_0=-107.)\n",
        "x,y = m(longitudes,latitudes)\n",
        "\n",
        "fig = plt.figure(figsize=(12,10))\n",
        "plt.title(\"All affected areas\")\n",
        "m.plot(x, y, \"o\", markersize = 2, color = 'blue')\n",
        "m.drawcoastlines()\n",
        "m.fillcontinents(color='coral',lake_color='aqua')\n",
        "m.drawmapboundary()\n",
        "m.drawcountries()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "esquoB-tudjD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X = final_data[['Timestamp', 'Latitude', 'Longitude']]\n",
        "y = final_data[['Magnitude', 'Depth']]\n",
        "from sklearn.cross_validation import train_test_split\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "print(X_train.shape, X_test.shape, y_train.shape, X_test.shape)"
      ],
      "metadata": {
        "id": "i8F61oi7uf5q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "\n",
        "def create_model(neurons, activation, optimizer, loss):\n",
        "    model = Sequential()\n",
        "    model.add(Dense(neurons, activation=activation, input_shape=(3,)))\n",
        "    model.add(Dense(neurons, activation=activation))\n",
        "    model.add(Dense(2, activation='softmax'))\n",
        "\n",
        "    model.compile(optimizer=optimizer, loss=loss, metrics=['accuracy'])\n",
        "\n",
        "    return model"
      ],
      "metadata": {
        "id": "OM7B_O1Tuhei"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "from keras.wrappers.scikit_learn import KerasClassifier\n",
        "\n",
        "model = KerasClassifier(build_fn=create_model, verbose=0)\n",
        "\n",
        "# neurons = [16, 64, 128, 256]\n",
        "neurons = [16]\n",
        "# batch_size = [10, 20, 50, 100]\n",
        "batch_size = [10]\n",
        "epochs = [10]\n",
        "# activation = ['relu', 'tanh', 'sigmoid', 'hard_sigmoid', 'linear', 'exponential']\n",
        "activation = ['sigmoid', 'relu']\n",
        "# optimizer = ['SGD', 'RMSprop', 'Adagrad', 'Adadelta', 'Adam', 'Adamax', 'Nadam']\n",
        "optimizer = ['SGD', 'Adadelta']\n",
        "loss = ['squared_hinge']\n",
        "\n",
        "param_grid = dict(neurons=neurons, batch_size=batch_size, epochs=epochs, activation=activation, optimizer=optimizer, loss=loss)"
      ],
      "metadata": {
        "id": "aiRdJSLSulOq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "grid = GridSearchCV(estimator=model, param_grid=param_grid, n_jobs=-1)\n",
        "grid_result = grid.fit(X_train, y_train)\n",
        "\n",
        "print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\n",
        "means = grid_result.cv_results_['mean_test_score']\n",
        "stds = grid_result.cv_results_['std_test_score']\n",
        "params = grid_result.cv_results_['params']\n",
        "for mean, stdev, param in zip(means, stds, params):\n",
        "    print(\"%f (%f) with: %r\" % (mean, stdev, param))"
      ],
      "metadata": {
        "id": "Nhk1XfBNun2C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = Sequential()\n",
        "model.add(Dense(16, activation='relu', input_shape=(3,)))\n",
        "model.add(Dense(16, activation='relu'))\n",
        "model.add(Dense(2, activation='softmax'))\n",
        "\n",
        "model.compile(optimizer='SGD', loss='squared_hinge', metrics=['accuracy'])\n",
        "model.fit(X_train, y_train, batch_size=10, epochs=20, verbose=1, validation_data=(X_test, y_test))\n",
        "\n",
        "[test_loss, test_acc] = model.evaluate(X_test, y_test)\n",
        "print(\"Evaluation result on Test Data : Loss = {}, accuracy = {}\".format(test_loss, test_acc))"
      ],
      "metadata": {
        "id": "38gZptJcupZC"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}